{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "source": [
    "import re\n",
    "import json\n",
    "from loguru import logger\n",
    "from tqdm import tqdm\n",
    "import openai\n",
    "\n",
    "client = openai.Client(base_url=\"http://127.0.0.1:30000/v1\", api_key=\"EMPTY\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "source": [
    "def get_prompt(problem, question, options):\n",
    "    options = '\\n'.join(f\"{'ABCDEFG'[i]}. {o}\" for i, o in enumerate(options))\n",
    "\n",
    "    prompt = f\"\"\"你是一个逻辑推理专家，擅长解决逻辑推理问题。以下是一个逻辑推理的题目，形式为单项选择题。所有的问题都是（close-world assumption）闭世界假设，即未观测事实都为假。题目如下：\n",
    "### 题目:\n",
    "{problem}\n",
    "### 问题:\n",
    "{question}\n",
    "{options}\n",
    "\"\"\"\n",
    "    return prompt + \"请通过逐步推理来解答问题，答案只有1个，并把最终答案放置于\\\\boxed{}中\"\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def process_datas(datas):\n",
    "    future_data = {}\n",
    "    lens = 0\n",
    "    for data in tqdm(datas, desc=\"Submitting tasks\", total=len(datas)):\n",
    "        problem = data['problem']\n",
    "        messages = []\n",
    "        for id, question in enumerate(data['questions']):\n",
    "            if 'answer' in question and question['answer'] in 'ABCDEFG':\n",
    "                continue\n",
    "                \n",
    "            prompt = get_prompt(problem,\n",
    "                                question['question'],\n",
    "                                question['options'],\n",
    "                                )\n",
    "            messages.append(prompt)\n",
    "            lens += 1\n",
    "        \n",
    "        if len(messages) == 0:\n",
    "            continue\n",
    "        response = client.completions.create(\n",
    "                            model=\"default\",\n",
    "                            prompt=messages,\n",
    "                            temperature=0,\n",
    "                            max_tokens=512\n",
    "                        )\n",
    "        \n",
    "        for choice in response.choices:\n",
    "            future_data[choice.text] = (data, choice.index)\n",
    "   \n",
    "    for future in tqdm(future_data, total=lens, desc=\"Processing tasks\"):\n",
    "        data = future_data[future][0]\n",
    "        problem_id = future_data[future][1]\n",
    "        try:\n",
    "            answer_pattern = re.compile(r\"boxed\\{([A-Z])\\}\", re.S)\n",
    "            answer = answer_pattern.findall(future)\n",
    "            if len(answer) != 1 or answer[0] not in 'ABCDEFG':\n",
    "                print(data[\"id\"])\n",
    "                continue\n",
    "                \n",
    "            data['questions'][problem_id]['answer'] = answer[0]\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to process text: {data}. Error: {e}\")\n",
    "\n",
    "    return datas"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def all_has_answer(test_data):\n",
    "    for item in test_data:\n",
    "        for id, question in enumerate(item['questions']):\n",
    "            if 'answer' not in question or question['answer'] not in 'ABCDEFG':\n",
    "                return False\n",
    "    return True"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "source": [
    "def main(ifn):\n",
    "    problems = []\n",
    "    # 按行读取数据\n",
    "    with open(ifn) as reader:\n",
    "        for line in reader:\n",
    "            sample = json.loads(line)\n",
    "            problems.append(sample)\n",
    "\n",
    "    index = 0\n",
    "    while not all_has_answer(problems) and index < 5:\n",
    "        problems = process_datas(problems)\n",
    "        index += 1\n",
    "    print(\"All tasks finished!\")\n",
    "    return problems"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "if __name__ == '__main__':\n",
    "    return_list = main('round1_test_data.jsonl')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "tags": []
   },
   "source": [
    "sorted_data = sorted(return_list, key=lambda x: int(str(x['id'])[-3:]))\n",
    "with open('upload-pipeline.jsonl', 'w') as writer:\n",
    "    for sample in sorted_data:\n",
    "        writer.write(json.dumps(sample, ensure_ascii=False))\n",
    "        writer.write('\\n')"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
